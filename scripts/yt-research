#!/usr/bin/env python3
"""
yt-research - Stream YouTube channel transcripts to Markdown

Usage: yt-research @channel_name
       yt-research https://www.youtube.com/@channel_name

Output: ./[channel_name].md in current directory
"""
import os
import sys

# Self-bootstrap: ensure we're running in the config venv
VENV_DIR = os.path.expanduser("~/.config/config-venv")
VENV_PYTHON = os.path.join(VENV_DIR, "bin", "python3")
if os.path.exists(VENV_PYTHON) and not sys.prefix.startswith(VENV_DIR):
    os.execv(VENV_PYTHON, [VENV_PYTHON] + sys.argv)

import asyncio
import argparse
import re
import urllib.error
import urllib.request
from pathlib import Path
from typing import Optional
import yt_dlp
from rich.progress import Progress, SpinnerColumn, TextColumn, BarColumn, TaskProgressColumn


def get_channel_name(channel_input: str) -> str:
    """Extract channel name from input (handle @name or URL)."""
    if channel_input.startswith('@'):
        return channel_input[1:]

    match = re.search(r'@([^/\s]+)', channel_input)
    if match:
        return match.group(1)

    match = re.search(r'/(?:c|channel)/([^/\s]+)', channel_input)
    if match:
        return match.group(1)

    return channel_input.strip('/')


def get_channel_url(channel_input: str) -> str:
    """Convert input to full channel URL."""
    if channel_input.startswith('http'):
        return channel_input
    if channel_input.startswith('@'):
        return f'https://www.youtube.com/{channel_input}'
    return f'https://www.youtube.com/@{channel_input}'


def clean_vtt_content(vtt_text: str) -> str:
    """Clean VTT format, return plain text with substring deduplication."""
    lines = []

    for line in vtt_text.split('\n'):
        if line.startswith('WEBVTT') or '-->' in line:
            continue
        if line.startswith(('Kind:', 'Language:')):
            continue
        if not line.strip():
            continue

        line = re.sub(r'<[\d:.]+>', '', line)
        line = re.sub(r'</?c[^>]*>', '', line)
        line = re.sub(r'</?[a-z][^>]*>', '', line)
        line = line.strip()

        if not line:
            continue

        # Hybrid deduplication: 'in' checks first, then overlap with min length
        MIN_OVERLAP = 4  # Minimum overlap to avoid false positives
        if lines:
            last = lines[-1]

            # First: try substring checks (catches most cases)
            if line in last:
                continue
            if last in line:
                lines[-1] = line
                continue

            # Second: try overlap merge with minimum length
            min_len = min(len(last), len(line))
            for overlap_len in range(min_len, MIN_OVERLAP - 1, -1):
                if last[-overlap_len:] == line[:overlap_len]:
                    lines[-1] = last + line[overlap_len:]
                    break
            else:
                lines.append(line)
            continue

        lines.append(line)

    text = ' '.join(lines)
    text = re.sub(r'\s+', ' ', text)
    text = re.sub(r'([.!?])\s+([A-Z])', r'\1\n\n\2', text)

    return text.strip()


def format_markdown_section(video_id: str, title: str, text: str) -> str:
    """Format a video transcript as a Markdown section."""
    return f"""## {title}
**Video ID:** {video_id}
**URL:** https://youtube.com/watch?v={video_id}

{text}

---

"""


def get_existing_video_ids(output_path: Path) -> set[str]:
    """Parse existing markdown file and extract already-processed video IDs."""
    if not output_path.exists():
        return set()

    try:
        content = output_path.read_text(encoding='utf-8')
        # Find all lines with "**Video ID:** {id}"
        video_ids = re.findall(r'\*\*Video ID:\*\* ([a-zA-Z0-9_-]+)', content)
        return set(video_ids)
    except Exception:
        return set()


class ProgressLogger:
    def __init__(self, verbose: bool = False, total: int = 0):
        self.verbose = verbose
        self.processed = 0
        self.skipped = 0
        self.failed = 0
        self.rate_limited = 0
        self.resumed = 0
        self.total = total
        self.progress = None
        self.task_id = None

    def start(self):
        if not self.verbose and self.total > 0:
            self.progress = Progress(
                SpinnerColumn(),
                TextColumn("[progress.description]{task.description}"),
                BarColumn(),
                TaskProgressColumn(),
                TextColumn("[cyan]{task.completed}/{task.total}"),
            )
            self.progress.start()
            self.task_id = self.progress.add_task("Processing videos", total=self.total)

    def stop(self):
        if self.progress:
            self.progress.stop()

    def _advance(self):
        if self.progress and self.task_id is not None:
            self.progress.advance(self.task_id)

    def _update_description(self, current_video: str = ""):
        """Update progress bar with current stats and video."""
        if self.progress and self.task_id is not None:
            stats = []
            if self.processed > 0:
                stats.append(f"[green]{self.processed} processed[/green]")
            if self.resumed > 0:
                stats.append(f"[blue]{self.resumed} resumed[/blue]")
            if self.skipped > 0:
                stats.append(f"[yellow]{self.skipped} skipped[/yellow]")
            if self.rate_limited > 0:
                stats.append(f"[red]{self.rate_limited} rate limited[/red]")
            if self.failed > 0:
                stats.append(f"[red]{self.failed} failed[/red]")

            stats_str = ", ".join(stats) if stats else "Starting..."

            if current_video:
                desc = f"{stats_str} | [cyan]Current:[/cyan] {current_video[:50]}..."
            else:
                desc = stats_str

            self.progress.update(self.task_id, description=desc)

    def set_current(self, title: str):
        """Set the current video being processed (updates progress bar)."""
        if not self.verbose:
            self._update_description(title)
        elif self.verbose:
            print(f"  [PROCESSING] {title[:60]}...")

    def log_processed(self, title: str):
        self.processed += 1
        self._advance()
        if self.verbose:
            print(f"  [âœ“] {title[:60]}...")
        else:
            self._update_description()

    def log_skipped(self, title: str, reason: str):
        self.skipped += 1
        self._advance()
        if self.verbose:
            print(f"  [SKIP] {title[:40]}... ({reason})")
        else:
            self._update_description()

    def log_failed(self, title: str, error: str):
        self.failed += 1
        self._advance()
        if self.verbose:
            print(f"  [FAIL] {title[:40]}... ({error})")
        else:
            self._update_description()

    def log_rate_limited(self, title: str):
        self.rate_limited += 1
        self._advance()
        if self.verbose:
            print(f"  [RATE LIMITED] {title[:40]}...")
        else:
            self._update_description()

    def log_resumed(self, title: str):
        self.resumed += 1
        self._advance()
        if self.verbose:
            print(f"  [RESUMED] {title[:40]}... (already exists)")
        else:
            self._update_description()

    def summary(self):
        self.stop()
        parts = [f"{self.processed} processed"]
        if self.resumed > 0:
            parts.append(f"{self.resumed} resumed")
        if self.skipped > 0:
            parts.append(f"{self.skipped} skipped")
        if self.rate_limited > 0:
            parts.append(f"{self.rate_limited} rate limited")
        if self.failed > 0:
            parts.append(f"{self.failed} failed")
        print(f"\nSummary: {', '.join(parts)}")


def fetch_video_subtitles(video_url: str, ydl_opts: dict) -> tuple[Optional[str], Optional[str]]:
    """Fetch subtitles for a single video. Returns (content, error_reason)."""
    opts = {
        **ydl_opts,
        'writeautomaticsub': True,
        'writesubtitles': True,
        'subtitlesformat': 'vtt',
        'subtitleslangs': ['en', 'en-US', 'en-GB', 'en-orig'],
        'skip_download': True,
    }

    with yt_dlp.YoutubeDL(opts) as ydl:
        try:
            info = ydl.extract_info(video_url, download=False)

            subtitles = info.get('subtitles', {})
            auto_subs = info.get('automatic_captions', {})
            sub_dict = subtitles if subtitles else auto_subs

            if not sub_dict:
                return None, "no subtitles"

            for lang in ['en', 'en-US', 'en-GB', 'en-orig']:
                if lang in sub_dict:
                    for fmt in sub_dict[lang]:
                        if fmt.get('ext') == 'vtt':
                            try:
                                with urllib.request.urlopen(fmt['url'], timeout=30) as response:
                                    return response.read().decode('utf-8'), None
                            except urllib.error.HTTPError as e:
                                if e.code == 429:
                                    return None, "rate limited"
                                return None, f"HTTP {e.code}"
                            except Exception as e:
                                return None, str(e)[:20]

            return None, "no English subs"
        except Exception as e:
            error_msg = str(e)[:30]
            if "429" in error_msg:
                return None, "rate limited"
            return None, error_msg


async def process_channel(channel_input: str, output_path: Path, progress: ProgressLogger):
    """Process all videos from a channel."""
    channel_url = get_channel_url(channel_input)
    channel_name = get_channel_name(channel_input)

    # Check for existing video IDs (resume functionality)
    existing_ids = get_existing_video_ids(output_path)
    if existing_ids:
        print(f"Found existing file with {len(existing_ids)} videos. Will resume...")

    print(f"Fetching video list from {channel_url}...")

    ydl_opts = {
        'quiet': True,
        'no_warnings': True,
        'extract_flat': True,
        'ignoreerrors': True,
    }

    videos = []
    with yt_dlp.YoutubeDL(ydl_opts) as ydl:
        try:
            # Fetch from both /videos and /shorts tabs
            for tab in ['/videos', '/shorts']:
                try:
                    result = ydl.extract_info(f"{channel_url}{tab}", download=False)
                    if result and 'entries' in result:
                        videos.extend([e for e in result['entries'] if e])
                except Exception:
                    pass  # Tab might not exist
        except Exception as e:
            print(f"Error fetching channel: {e}")
            return

    if not videos:
        print("No videos found.")
        return

    print(f"Found {len(videos)} videos. Processing...")

    # Set total and start progress bar
    progress.total = len(videos)
    progress.start()

    # Only write header if this is a new file
    if not existing_ids:
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(f"# {channel_name}\n\n")

    semaphore = asyncio.Semaphore(5)

    async def process_video(video_info: dict):
        async with semaphore:
            video_id = video_info.get('id')
            title = video_info.get('title', 'Unknown Title')

            if not video_id:
                progress.log_skipped(title, "no video ID")
                return None

            # Skip if already processed
            if video_id in existing_ids:
                progress.log_resumed(title)
                return None

            # Show current video being processed
            progress.set_current(title)

            video_url = f"https://www.youtube.com/watch?v={video_id}"

            loop = asyncio.get_event_loop()
            try:
                vtt_content, error_reason = await loop.run_in_executor(
                    None,
                    fetch_video_subtitles,
                    video_url,
                    {'quiet': True, 'no_warnings': True}
                )
            except Exception as e:
                progress.log_failed(title, str(e)[:30])
                return None

            if not vtt_content:
                # Check if it's a rate limit error
                if error_reason == "rate limited":
                    progress.log_rate_limited(title)
                else:
                    progress.log_skipped(title, error_reason or "unknown error")
                return None

            cleaned_text = clean_vtt_content(vtt_content)
            if not cleaned_text:
                progress.log_skipped(title, "empty transcript")
                return None

            section = format_markdown_section(video_id, title, cleaned_text)
            progress.log_processed(title)
            return section

    tasks = [process_video(v) for v in videos]
    results = await asyncio.gather(*tasks, return_exceptions=True)

    with open(output_path, 'a', encoding='utf-8') as f:
        for result in results:
            if isinstance(result, str) and result:
                f.write(result)


def main():
    parser = argparse.ArgumentParser(
        description='Stream YouTube channel transcripts to Markdown',
        usage='yt-research @channel_name'
    )
    parser.add_argument('channel', help='Channel name (@name) or URL')
    parser.add_argument('-o', '--output', help='Output file path (default: ./[channel].md)')
    parser.add_argument('-v', '--verbose', action='store_true', help='Show detailed progress for each video')

    args = parser.parse_args()

    channel_name = get_channel_name(args.channel)
    if args.output:
        output_path = Path(args.output)
    else:
        output_path = Path.cwd() / f'{channel_name}.md'

    print(f"Output: {output_path}")

    progress = ProgressLogger(verbose=args.verbose)
    asyncio.run(process_channel(args.channel, output_path, progress))

    progress.summary()
    print(f"\nDone! Output written to: {output_path}")


if __name__ == '__main__':
    main()
